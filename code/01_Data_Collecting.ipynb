{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Web APIs & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data from reddit\n",
    "Using Pushshift Reddit API, get data from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is from r/sewing\n",
    "sew_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "sew_params = {\n",
    "    'subreddit': 'sewing',\n",
    "    'size': 100,\n",
    "    'before': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is from r/3dprinting\n",
    "printing3d_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "printing3d_params = {\n",
    "    'subreddit': '3Dprinting',\n",
    "    'size': 100,\n",
    "    'before': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from reddit\n",
    "def get_data(url, params, iteration=20):\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for _ in range(iteration):\n",
    "\n",
    "        res = get_retry(url, params, 3)\n",
    "        \n",
    "        if res.status_code != 200:\n",
    "            continue\n",
    "        \n",
    "        # convert the data\n",
    "        data = res.json()\n",
    "        \n",
    "        posts = data['data']\n",
    "        \n",
    "        for post in posts:\n",
    "            data_list.append(post)\n",
    "        \n",
    "        # get the utc for the before parameter from the last of the list\n",
    "        # we can get posts data only 100, so have to request over and over\n",
    "        params['before'] = posts[-1]['created_utc']\n",
    "        \n",
    "        # decrease the loads for the website\n",
    "        time.sleep(2)\n",
    "        \n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "# if the status codes were 500, 502, 505, retry\n",
    "def get_retry(url, params, retry_times):\n",
    "    for t in range(retry_times + 1):\n",
    "        res = requests.get(url, params)\n",
    "        if t < retry_times:\n",
    "            if res.status_code in [500, 502, 505]:\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sew = get_data(sew_url, sew_params)\n",
    "data_3dprint = get_data(printing3d_url, printing3d_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sew.to_csv('../data/sewing_raw.csv', index=False)\n",
    "data_3dprint.to_csv('../data/3dprinting_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
