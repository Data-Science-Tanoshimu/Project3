{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/final.csv')\n",
    "\n",
    "df['sewing'] = df['subreddit'].apply(lambda x: 1 if x == 'sewing' else 0)\n",
    "\n",
    "X = df['combined_text']\n",
    "y = df['sewing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate models and compare the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model function\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caluculate scores\n",
    "def cal_scores(model_filename, test_X, test_y):\n",
    "    scores = {}\n",
    "    \n",
    "    model = load_model(model_filename)\n",
    "    \n",
    "    scores['best_score'] = model.best_score_\n",
    "    \n",
    "    scores['test_score'] = model.best_estimator_.score(test_X, test_y)\n",
    "    \n",
    "    scores['recall'] = recall_score(model.best_estimator_.predict(test_X), test_y)\n",
    "    \n",
    "    scores['precision'] = precision_score(model.best_estimator_.predict(test_X), test_y)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cvec_scores = cal_scores('../model/classification_models/logreg_cvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9261016949152543,\n",
       " 'test_score': 0.9024390243902439,\n",
       " 'recall': 0.9402654867256637,\n",
       " 'precision': 0.8603238866396761}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cvec_scores = cal_scores('../model/classification_models/knn_cvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.8410169491525423,\n",
       " 'test_score': 0.8150406504065041,\n",
       " 'recall': 0.8861386138613861,\n",
       " 'precision': 0.7246963562753036}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial naive bayes with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_cvec_scores = cal_scores('../model/classification_models/mnb_cvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9006779661016949,\n",
       " 'test_score': 0.8953252032520326,\n",
       " 'recall': 0.8654205607476636,\n",
       " 'precision': 0.937246963562753}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_cvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cvec_scores = cal_scores('../model/classification_models/rf_cvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9193220338983051,\n",
       " 'test_score': 0.8922764227642277,\n",
       " 'recall': 0.9641148325358851,\n",
       " 'precision': 0.8157894736842105}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine with cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_cvec_scores = cal_scores('../model/classification_models/svc_cvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.892542372881356,\n",
       " 'test_score': 0.8699186991869918,\n",
       " 'recall': 0.9399038461538461,\n",
       " 'precision': 0.791497975708502}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tvec_scores = cal_scores('../model/classification_models/logreg_tvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9169491525423729,\n",
       " 'test_score': 0.9034552845528455,\n",
       " 'recall': 0.9290322580645162,\n",
       " 'precision': 0.8744939271255061}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tvec_scores = cal_scores('../model/classification_models/knn_tvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.8525423728813559,\n",
       " 'test_score': 0.8323170731707317,\n",
       " 'recall': 0.853763440860215,\n",
       " 'precision': 0.8036437246963563}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial naive bayes with tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tvec_scores = cal_scores('../model/classification_models/mnb_tvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9172881355932203,\n",
       " 'test_score': 0.9024390243902439,\n",
       " 'recall': 0.898,\n",
       " 'precision': 0.9089068825910931}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian naive bayes with tvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't use GridSearch for Gaussian naive bayes, but the best cross validation score was about 0.929 in '03_Modeling.ipynb'. This pickled model doesn't have best score in the object, so those scores are calculated without the function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnb_tvec = load_model('../model/classification_models/gnb_tvec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_500 = TfidfVectorizer(max_features=500, stop_words='english', ngram_range=(1,2))\n",
    "\n",
    "tvec_500_train = tvec_500.fit_transform(X_train)\n",
    "tvec_500_test = tvec_500.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_tvec_scores = {\n",
    "    'best_score': 0.929,\n",
    "    'test_score': gnb_tvec.score(tvec_500_test.todense(), y_test),\n",
    "    'recall': recall_score(gnb_tvec.predict(tvec_500_test.todense()), y_test),\n",
    "    'precision': precision_score(gnb_tvec.predict(tvec_500_test.todense()), y_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.929,\n",
       " 'test_score': 0.9217479674796748,\n",
       " 'recall': 0.9503239740820735,\n",
       " 'precision': 0.8906882591093117}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the vectorizer for an app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/transformers/gnb_vectorizer.pickle', 'wb') as model:\n",
    "        pickle.dump(tvec_500, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tvec_scores = cal_scores('../model/classification_models/rf_tvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9183050847457627,\n",
       " 'test_score': 0.8800813008130082,\n",
       " 'recall': 0.9541062801932367,\n",
       " 'precision': 0.7995951417004049}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine with tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tvec_scores = cal_scores('../model/classification_models/svc_tvec_gs.pickle', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.9074576271186441,\n",
       " 'test_score': 0.8973577235772358,\n",
       " 'recall': 0.9225806451612903,\n",
       " 'precision': 0.868421052631579}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_tvec_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a score table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Best score | Test score | Recall | Precision |\n",
    "|:---------|:---------|:---------|:---------| |\n",
    "|**Logistic regression with cvec** | 0.926 | 0.902 | 0.940 | 0.860 |\n",
    "|**KNN with cvec** | 0.841 | 0.815 | 0.886 | 0.725 |\n",
    "|**Mulitinoimal naive bayes with cvec** | 0.901 | 0.895 | 0.865 | 0.937 |\n",
    "|**Random forest with cvec** | 0.919 | 0.892 | 0.964 | 0.816 |\n",
    "|**SVC with cvec** | 0.893 | 0.870 | 0.940 | 0.791 |\n",
    "|**Logistic regression with tvec** | 0.917 | 0.903 | 0.929 | 0.874 |\n",
    "|**KNN with tvec**| 0.853 | 0.832 | 0.854 | 0.804 |\n",
    "|**Multinomial naive bayes with tvec** | 0.917 | 0.902 | 0.898 | 0.909 |\n",
    "|**Gaussian naive bayes with tvec**| 0.929 | 0.922 | 0.950 | 0.891 |\n",
    "|**Random forest with tvec**| 0.918 | 0.880 | 0.954 | 0.800 |\n",
    "|**SVC with tvec**| 0.907 | 0.897 | 0.923 | 0.868 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the gaussian naive bayes as the best model, because it is the highest score for the test score and looks like it is not overfitting compared to other models.\n",
    "\n",
    "The parameters of the model is TfidfVectorizer(max_features=500, stop_words='english', ngram_range=(1,2) and GaussianNB(var_smoothing=4.45)\n",
    "\n",
    "This projet is impartial for both subreddits since there is no weight on each subreddit unlike a spam filter. However, if this model for the spam filter, we want to prevent that a ham would go to a spam mail folder. In that case, we increase the precision score changing the model threshold and reducing the false positives. But the recall and precision is a trade-off relationship, so we have to care about both scores.\n",
    "\n",
    "*I made an app to judge which subreddit a post is from. The code is in app folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
